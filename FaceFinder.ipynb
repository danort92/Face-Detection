{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danort92/Face-Detection/blob/main/FaceFinder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FaceFinder - A Face Detection Model**"
      ],
      "metadata": {
        "id": "SzVz-GE05CRl"
      },
      "id": "SzVz-GE05CRl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook I am going to develop a Face Detection Model given a photo as input. I won't use pre-trained models, but will create my own from scratch.\n",
        "\n",
        "I will use imgaug library to manage images and scikit-learn functions"
      ],
      "metadata": {
        "id": "nj_wcb0dzMPl"
      },
      "id": "nj_wcb0dzMPl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81a85a67",
      "metadata": {
        "scrolled": false,
        "id": "81a85a67"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python\n",
        "!pip install imgaug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f91becae",
      "metadata": {
        "id": "f91becae"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import glob\n",
        "import collections\n",
        "import pickle\n",
        "import time\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import imgaug as ia\n",
        "import imgaug.augmenters as iaa\n",
        "from imgaug.augmenters import Fliplr, Flipud, Affine\n",
        "from itertools import chain\n",
        "from skimage import data, color, feature\n",
        "import skimage.data\n",
        "from skimage.transform import resize\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.svm import SVC,LinearSVC\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ad459d4b",
      "metadata": {
        "id": "ad459d4b"
      },
      "outputs": [],
      "source": [
        "#say no to warnings!\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f876ecc1",
      "metadata": {
        "id": "f876ecc1"
      },
      "source": [
        "## IMPORT DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I will train the model using positive and negative images from Caltech dataset. It contains 6713 positive (w/ faces) and 275 negative (w/o faces) images."
      ],
      "metadata": {
        "id": "Zd_VrppV6VNB"
      },
      "id": "Zd_VrppV6VNB"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "222357a4",
      "metadata": {
        "id": "222357a4"
      },
      "outputs": [],
      "source": [
        "def create_img_array(path, patch_size=(36,36)):\n",
        "    \"\"\"\n",
        "    FUNC: creation of an array of grey images with predefined size\n",
        "    ARGS: \n",
        "        - path: string; the path of images set\n",
        "        - patch_size: (2,) tuple; the pixel dimensionality of images \n",
        "          (default=(36,36), that's the dimensions of Caltech_CropFaces positive images imported. \n",
        "          With other sets you can change it to other dimensions)\n",
        "    RETURN:\n",
        "        - img_array: (N,2) ndarray; N is the number of images and each row represents width and height.\n",
        "    \"\"\"\n",
        "    img_array=[]\n",
        "    for file in path:\n",
        "        image = cv2.imread (file)\n",
        "        image = cv2.resize(image, dsize=patch_size)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        img_array.append(image)\n",
        "    return img_array"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/danort92/Face-Detection.git\n",
        "pos_path=\"/Face-Detection/sets/train_positive_set/Caltech_CropFaces\"\n",
        "neg_path=\"/Face-Detection/sets/train_negative_set\"\n",
        "pos_set=create_img_array(glob.glob (os.getcwd() + pos_path + \"/*.jpg\"))\n",
        "neg_set=create_img_array(glob.glob (os.getcwd() + neg_path + \"/*.jpg\"))"
      ],
      "metadata": {
        "id": "tTGrSCC9rEVL"
      },
      "id": "tTGrSCC9rEVL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "32e037ae",
      "metadata": {
        "id": "32e037ae"
      },
      "outputs": [],
      "source": [
        "#function to show a subset of the images array previously created\n",
        "def show_img_subplot(img_set):\n",
        "    fig, ax = plt.subplots(4, 8, figsize=(10, 4))\n",
        "    n_images=np.array(img_set).shape[0]\n",
        "    for i, axi in enumerate(ax.flat):\n",
        "        k=np.random.choice(n_images,1)[0]\n",
        "        axi.imshow(img_set[k], cmap='gray')\n",
        "        axi.axis('off')    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24f90b70",
      "metadata": {
        "id": "24f90b70"
      },
      "source": [
        "## DATA AUGMENTATION"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset is augmented with slightly modified images. Negative pics are horizontally and vertically flipped, rotated and cropped. Positive pics are just mirrored (applying the same modifies as done for the negative set I've seen to be linked to many false positives, so I preferred only the less invasive modification)"
      ],
      "metadata": {
        "id": "5N-9EMoN7VIm"
      },
      "id": "5N-9EMoN7VIm"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9c6d28bb",
      "metadata": {
        "id": "9c6d28bb"
      },
      "outputs": [],
      "source": [
        "#original script found on https://imgaug.readthedocs.io/ and slightly modified in order to perform data augmentation\n",
        "\n",
        "def img_neg_augmentation(img_set,neg_k=1):\n",
        "    \"\"\"\n",
        "    FUNC: Data augmentation through different techniques (horiziontal flip, vertical flip, rotation and shear)\n",
        "          Images are randomly chosen through random choice of index\n",
        "    ARGS: \n",
        "        - img_set: (N,2) ndarray; N is the number of negative images and each row represents width and height.\n",
        "        - neg_k:  constant, multiplier of images randomly chosen from the original set\n",
        "    RETURN:\n",
        "        - aug_set: (M,2) ndarray; M is the number of negative images (M>N) and each row represents width and height\n",
        "    \"\"\"\n",
        "\n",
        "    n_images=np.array(img_set).shape[0]\n",
        "    aug_set=[]\n",
        "    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "\n",
        "    for i in range(1,int(neg_k/4*n_images)):\n",
        "        r=np.random.choice(n_images,1)[0]\n",
        "        \n",
        "        hflip= iaa.Fliplr(p=0.6)\n",
        "        aug_hor_image= hflip.augment_image(img_set[r])\n",
        "        aug_set.append(aug_hor_image)\n",
        "        \n",
        "        vflip= iaa.Flipud(p=0.2)\n",
        "        aug_ver_image= vflip.augment_image(img_set[r])\n",
        "        aug_set.append(aug_ver_image)\n",
        "        \n",
        "        aff = sometimes(iaa.Affine(scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)},\n",
        "                    translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)},\n",
        "                    rotate=(-25, 25),\n",
        "                    shear=(-30, 30),\n",
        "                    order=[0, 1],\n",
        "                    cval=(0, 255),\n",
        "                    mode=ia.ALL))\n",
        "        aug_aff_image= aff.augment_image(img_set[r])\n",
        "        aug_set.append(aug_aff_image)\n",
        "        \n",
        "        crop=sometimes(iaa.Crop(percent=(0, 0.1)))\n",
        "        aug_crop_image= crop.augment_image(img_set[r])\n",
        "        aug_set.append(aug_crop_image)\n",
        "\n",
        "    return aug_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ba0c811b",
      "metadata": {
        "id": "ba0c811b"
      },
      "outputs": [],
      "source": [
        "#original script found on https://imgaug.readthedocs.io/ and slightly modified in order to perform data augmentation\n",
        "\n",
        "def img_pos_augmentation(img_set,pos_k):\n",
        "    \"\"\"\n",
        "    FUNC: Data augmentation only through horiziontal flip \n",
        "          (applying the same techniques used for negative set there would be many more false positives)\n",
        "          Images are randomly chosen through random choice of index\n",
        "    ARGS: \n",
        "        - img_set: (N,2) ndarray; N is the number of positive images and each row represents width and height.\n",
        "        - pos_k:  constant, multiplier of images randomly chosen from the original set\n",
        "    RETURN:\n",
        "        - aug_set: (M,2) ndarray; M is the number of positive images (M>N) and each row represents width and height\n",
        "    \"\"\"\n",
        "\n",
        "    n_images=np.array(img_set).shape[0]\n",
        "    aug_set=[]\n",
        "    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "\n",
        "    for i in range(1,int(pos_k*n_images)):\n",
        "        r=np.random.choice(n_images,1)[0]\n",
        "        \n",
        "        hflip= iaa.Fliplr(p=0.6)\n",
        "        aug_hor_image= hflip.augment_image(img_set[r])\n",
        "        aug_set.append(aug_hor_image)\n",
        "        \n",
        "    return aug_set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d05f9ae2",
      "metadata": {
        "id": "d05f9ae2"
      },
      "source": [
        "## SVM MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A linear Support Vector Machine model is used. Hyperparameters are optimized through the script found on https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV. It iterates to find the best estimators for the binary classification model GridSearchCV"
      ],
      "metadata": {
        "id": "JJHvXToO6GlK"
      },
      "id": "JJHvXToO6GlK"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7a6aaa2f",
      "metadata": {
        "id": "7a6aaa2f"
      },
      "outputs": [],
      "source": [
        "def print_dataframe(filtered_cv_results):\n",
        "    \"\"\"Pretty print for filtered dataframe\"\"\"\n",
        "    for mean_precision, std_precision, mean_recall, std_recall, params in zip(\n",
        "        filtered_cv_results[\"mean_test_precision\"],\n",
        "        filtered_cv_results[\"std_test_precision\"],\n",
        "        filtered_cv_results[\"mean_test_recall\"],\n",
        "        filtered_cv_results[\"std_test_recall\"],\n",
        "        filtered_cv_results[\"params\"],\n",
        "    ):\n",
        "        print(\n",
        "            f\"precision: {mean_precision:0.3f} (±{std_precision:0.03f}),\"\n",
        "            f\" recall: {mean_recall:0.3f} (±{std_recall:0.03f}),\"\n",
        "            f\" for {params}\"\n",
        "        )\n",
        "    print()\n",
        "\n",
        "\n",
        "def refit_strategy(cv_results):\n",
        "    \"\"\"Define the strategy to select the best estimator.\n",
        "\n",
        "    The strategy defined here is to filter-out all results below a precision threshold\n",
        "    of 0.97, rank the remaining by recall and keep all models with one standard\n",
        "    deviation of the best by recall. Once these models are selected, we can select the\n",
        "    fastest model to predict.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    cv_results : dict of numpy (masked) ndarrays\n",
        "        CV results as returned by the `GridSearchCV`.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    best_index : int\n",
        "        The index of the best estimator as it appears in `cv_results`.\n",
        "    \"\"\"\n",
        "    # print the info about the grid-search for the different scores\n",
        "    precision_threshold = 0.97\n",
        "\n",
        "    cv_results_ = pd.DataFrame(cv_results)\n",
        "    print(\"All grid-search results:\")\n",
        "    print_dataframe(cv_results_)\n",
        "\n",
        "    # Filter-out all results below the threshold\n",
        "    high_precision_cv_results = cv_results_[\n",
        "        cv_results_[\"mean_test_precision\"] > precision_threshold\n",
        "    ]\n",
        "\n",
        "    print(f\"Models with a precision higher than {precision_threshold}:\")\n",
        "    print_dataframe(high_precision_cv_results)\n",
        "\n",
        "    high_precision_cv_results = high_precision_cv_results[\n",
        "        [\n",
        "            \"mean_score_time\",\n",
        "            \"mean_test_recall\",\n",
        "            \"std_test_recall\",\n",
        "            \"mean_test_precision\",\n",
        "            \"std_test_precision\",\n",
        "            \"rank_test_recall\",\n",
        "            \"rank_test_precision\",\n",
        "            \"params\",\n",
        "        ]\n",
        "    ]\n",
        "\n",
        "    # Select the most performant models in terms of recall\n",
        "    # (within 1 sigma from the best)\n",
        "    best_recall_std = high_precision_cv_results[\"mean_test_recall\"].std()\n",
        "    best_recall = high_precision_cv_results[\"mean_test_recall\"].max()\n",
        "    best_recall_threshold = best_recall - best_recall_std\n",
        "\n",
        "    high_recall_cv_results = high_precision_cv_results[\n",
        "        high_precision_cv_results[\"mean_test_recall\"] > best_recall_threshold\n",
        "    ]\n",
        "    print(\n",
        "        \"Out of the previously selected high precision models, we keep all the\\n\"\n",
        "        \"the models within one standard deviation of the highest recall model:\"\n",
        "    )\n",
        "    print_dataframe(high_recall_cv_results)\n",
        "\n",
        "    # From the best candidates, select the fastest model to predict\n",
        "    fastest_top_recall_high_precision_index = high_recall_cv_results[\n",
        "        \"mean_score_time\"\n",
        "    ].idxmin()\n",
        "\n",
        "    print(\n",
        "        \"\\nThe selected final model is the fastest to predict out of the previously\\n\"\n",
        "        \"selected subset of best models based on precision and recall.\\n\"\n",
        "        \"Its scoring time is:\\n\\n\"\n",
        "        f\"{high_recall_cv_results.loc[fastest_top_recall_high_precision_index]}\"\n",
        "    )\n",
        "\n",
        "    return fastest_top_recall_high_precision_index"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformation of images in HOG vectors is performed, because HOG relies on the property of objects within an image to possess the distribution of intensity gradients or edge directions. \n",
        "              Gradients are calculated within an image per patch. A patch is considered as a pixel grid in which gradients \n",
        "              are constituted from the magnitude and direction of change in the intensities of the pixel within the patch."
      ],
      "metadata": {
        "id": "_5EeBlx16lFl"
      },
      "id": "_5EeBlx16lFl"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cbc42212",
      "metadata": {
        "id": "cbc42212"
      },
      "outputs": [],
      "source": [
        "def train_classifier(pos_set,neg_set,pixel_per_cell=(6,6)):\n",
        "\n",
        "    \"\"\"\n",
        "    FUNC: 1 - The train features and labels are created from predefined positive and negative sets.\n",
        "          2 - The images are transformed in vectors through HOG feature from skimage library\n",
        "          3 - A Linear Support Vector Classification model is then trained in order to optimize precision and recall through cross-validation.\n",
        "    ARGS:\n",
        "        - pos_set: (N,2) ndarray; N is the number of positive images and each row is width and height.\n",
        "        - neg_set: (N,2) ndarray; N is the number of negative images and each row is width and height.\n",
        "    RETURN:\n",
        "        - model: the model fitted with best found estimators \n",
        "    \"\"\"\n",
        "\n",
        "    X_train = np.array([feature.hog(im, pixels_per_cell=pixel_per_cell)\n",
        "                        for im in chain(pos_set,\n",
        "                                        neg_set)])\n",
        "    y_train = np.zeros(X_train.shape[0])\n",
        "    y_train[:np.shape(pos_set)[0]] = 1\n",
        "    \n",
        "    scoring = ['precision','recall']\n",
        "    grid = GridSearchCV(LinearSVC(random_state=1), \n",
        "                        {\"C\": [0.001,0.0025,0.005,0.01,0.025,0.05]},\n",
        "                        scoring=scoring,\n",
        "                        verbose=2,\n",
        "                       refit=refit_strategy)\n",
        "    grid.fit(X_train, y_train)\n",
        "    \n",
        "    model = grid.best_estimator_\n",
        "    model.fit(X_train, y_train)\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5370a7f",
      "metadata": {
        "id": "f5370a7f"
      },
      "source": [
        "## TESTING"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "During the testing phase a sliding window approach is used to slide on the image given a fixed step and find the patches' confidence. The patches with confidence higher than a positive threshold are considered as bounding boxes with enough probability to contain a face. Overlapping bounding boxes with lower confidences are then suppressed. Patches with confidence lower than a negative threshold, instead, have a high probability to not contain any faces and are saved for a subsequent hard mining phase where they aer used to manually boost the model"
      ],
      "metadata": {
        "id": "b3H1mAYx7G3A"
      },
      "id": "b3H1mAYx7G3A"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b8b85248",
      "metadata": {
        "id": "b8b85248"
      },
      "outputs": [],
      "source": [
        "def non_max_supr_bbox(bboxes, confidences, img_size):\n",
        "\n",
        "    \"\"\"\n",
        "    FUNC: high confidence detections suppress all overlapping detections\n",
        "        (including detections at other scales). Detections can partially\n",
        "        overlap, but the center of one detection can not be within another\n",
        "        detection.\n",
        "    ARGS:\n",
        "        - bboxes: (N,4) ndarray; N is the number of non-overlapping detections,\n",
        "                  and each row is [x_min, y_min, x_max, y_max].\n",
        "        - confidences: (N,1) ndarray; Confidence of each detection after final\n",
        "                  cascade node.\n",
        "        - img_size: (2,) list; width and height of the image.\n",
        "    RETURN:\n",
        "        - is_valid_bbox: (N,1) bool ndarray; indicating valid bounding boxes.\n",
        "    \"\"\"\n",
        "\n",
        "    #Truncate bounding boxes to image dimensions\n",
        "    x_out_of_bounds=bboxes[:,2] > img_size[1]  #xmax greater than x dimension\n",
        "    y_out_of_bounds=bboxes[:,3] > img_size[0]  #ymax greater than y dimension\n",
        "    bboxes[x_out_of_bounds,2]=img_size[1]\n",
        "    bboxes[y_out_of_bounds,3]=img_size[0]\n",
        "\n",
        "    num_detections=confidences.shape[0]\n",
        "\n",
        "    #higher confidence detections get priority\n",
        "    ind=np.argsort(-confidences, axis=0).ravel()\n",
        "    bboxes=bboxes[ind,:]\n",
        "\n",
        "    #indicator for whether each bbox will be accepted or suppressed\n",
        "    is_valid_bbox=np.zeros((num_detections,1),dtype=np.bool)\n",
        "    for i in range(num_detections):\n",
        "        cur_bb=bboxes[i,:]\n",
        "        cur_bb_is_valid=True\n",
        "\n",
        "        for j in np.where(is_valid_bbox)[0]:\n",
        "            prev_bb=bboxes[j,:]\n",
        "            bi=[max(cur_bb[0], prev_bb[0]),\n",
        "                max(cur_bb[1], prev_bb[1]),\n",
        "                min(cur_bb[2], prev_bb[2]),\n",
        "                min(cur_bb[3], prev_bb[3])]\n",
        "            iw=bi[2]-bi[0]+1\n",
        "            ih=bi[3]-bi[1]+1\n",
        "\n",
        "            if iw>0 and ih>0:\n",
        "                #compute overlap as area of intersection / area of union\n",
        "                ua=(cur_bb[2] - cur_bb[0] + 1) * (cur_bb[3] - cur_bb[1] + 1) + \\\n",
        "                     (prev_bb[2] - prev_bb[0] + 1) * (prev_bb[3] - prev_bb[1] + 1) - \\\n",
        "                     iw * ih\n",
        "                ov = iw * ih / ua\n",
        "\n",
        "                #if the less confident detection overlaps too much with the previous detection\n",
        "                if ov>0.2:\n",
        "                    cur_bb_is_valid=False\n",
        "\n",
        "                center_coord=[(cur_bb[0] + cur_bb[2]) / 2, (cur_bb[1] + cur_bb[3]) / 2]\n",
        "                if (center_coord[0] > prev_bb[0]) and (center_coord[0] < prev_bb[2]) and \\\n",
        "                        (center_coord[1] > prev_bb[1]) and (center_coord[1] < prev_bb[3]):\n",
        "                    cur_bb_is_valid=False\n",
        "\n",
        "        is_valid_bbox[i]=cur_bb_is_valid\n",
        "\n",
        "    #This statement returns the logical array 'is_valid_bbox' back to the order\n",
        "    #of the input bboxes and confidences\n",
        "    reverse_map=np.zeros((num_detections,), dtype=np.int)\n",
        "    reverse_map[ind]=np.arange(num_detections)\n",
        "    is_valid_bbox=is_valid_bbox[reverse_map,:]\n",
        "\n",
        "    return is_valid_bbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cf974046",
      "metadata": {
        "id": "cf974046"
      },
      "outputs": [],
      "source": [
        "def sliding_window(path, patch_size=(36,36), pixel_per_cell=(6,6), step=3, p_threshold=1, n_threshold=-0.5, downsample=0.8, verbose=False):\n",
        "\n",
        "    \"\"\"\n",
        "    FUNC: a patch of predefined size slides on the image with a specific step.\n",
        "          1 - For each step i) the image is transformed through Histogram Of Gradients (HOG) function\n",
        "              and ii) a confidence level is calculated based on the trained model. \n",
        "          2 - If the conficence is higher than a predefined threshold the patch is kept because it has \n",
        "              a relatively high probability to contain a face. A negative threshold is also set to keep patch with a low confidence\n",
        "              (to eventually perform a negative hard mining, including those pathces in the train set manually boost the model)\n",
        "          3 - The previous points are repeated at different scales (there could be faces with different dimensions inside the image) \n",
        "    ARGS:\n",
        "        - path: string - the path of the image\n",
        "        - patch_size: (2,) tuple; pixel dimensions of the patch (Width,Height)\n",
        "        - step: constant; pixel step between two condecutive patches and defining the sliding window mechanism\n",
        "        - p_threshold: constant; threshold for high confidence patches (default=1, the lower the higher the risk of false positives)\n",
        "        - n_threshold: constant; threshold for low confidence patches (default=-0.5, the lower )\n",
        "        - downsample: constant; the parameter defines the quantity the image is scaled after each loop\n",
        "        - verbose: boolean; shows some interesting parameters (default=False)  \n",
        "    RETURN:\n",
        "        - plt.show(): plot of the image together with the detected bounding boxes\n",
        "    \"\"\"\n",
        "    \n",
        "    img_name=os.listdir(path)\n",
        "    \n",
        "    bboxes = np.zeros([0, 4])\n",
        "    confidences = np.zeros([0, 1])\n",
        "    \n",
        "    hard_neg_set=[]\n",
        "    k=0\n",
        "     \n",
        "    img = cv2.imread(os.path.join(path, img_name[0]))\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    #process starts from an initial scale defined by this ratio\n",
        "    #because i) there would be much more false positives and ii) no camera gets to detected very small faces in an image\n",
        "    scale_factor=4*patch_size[0]/min(img.shape[0],img.shape[1])\n",
        "    \n",
        "    W, H = (int(s) for s in patch_size)\n",
        "    print(\"------------------------------------------\")\n",
        "    print(\"Detection STARTED...\\n\")\n",
        "    \n",
        "    while min(img.shape[0],img.shape[1])*scale_factor >= patch_size[0]:\n",
        "    \n",
        "        img_re=resize(img, (int(img.shape[0]*scale_factor), int(img.shape[1]*scale_factor)))\n",
        "        \n",
        "        \n",
        "        for i in range(0, img_re.shape[0] - W, step):\n",
        "            for j in range(0, img_re.shape[1] - H, step):\n",
        "                  \n",
        "                patch = img_re[i:i + W, j:j + H]\n",
        "                patch_hog = feature.hog(patch, pixels_per_cell=pixel_per_cell)\n",
        "            \n",
        "                confidence = model.decision_function(patch_hog.reshape(1, -1))\n",
        "                if confidence>=p_threshold:\n",
        "                    \n",
        "                    x_min = j/scale_factor\n",
        "                    y_min = i/scale_factor\n",
        "                    x_max = (j+W)/scale_factor\n",
        "                    y_max = (i+H)/scale_factor\n",
        "\n",
        "                    bboxes = np.concatenate((bboxes, [[x_min, y_min, x_max, y_max]]), 0)\n",
        "                    confidences = np.concatenate((confidences, [confidence]), 0)\n",
        "\n",
        "                elif confidence<n_threshold:\n",
        "                    hard_neg_set.append(patch)\n",
        "        if verbose:\n",
        "          print(f\"{k+1}° loop completed --> Scale factor: {scale_factor*100:.2f}%\")\n",
        "           \n",
        "        k+=1          \n",
        "        scale_factor = scale_factor * downsample\n",
        "        \n",
        "    #added to remove bounding boxes overlapping each others, with preference to higher confidence\n",
        "    is_maximum = non_max_supr_bbox(bboxes, confidences, img.shape)\n",
        "\n",
        "    bboxes = bboxes[is_maximum[:, 0], :]\n",
        "    confidences = confidences[is_maximum[:, 0], :] \n",
        "    print(\"\\nDetection COMPLETED!\")\n",
        "    print(\"------------------------------------------\\n\")\n",
        "    print(f\"Bounding boxes found: {len(bboxes)}\\n\") \n",
        "    return bboxes, confidences, hard_neg_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4eba0331",
      "metadata": {
        "scrolled": true,
        "id": "4eba0331"
      },
      "outputs": [],
      "source": [
        "# function that plots images with corresponding bounding boxes\n",
        "def show_bboxes(path,bboxes):\n",
        "\n",
        "    \"\"\"\n",
        "    FUNC: shows high confidence bounding boxes after sliding window algorithm \n",
        "          and suppression of lower confidence overlapping bounding boxes\n",
        "          if there are no detected bounding boxes the function prints that no faces have been detected, \n",
        "          otherwise it shows how many bounding boxes have been found and their coordinates \n",
        "    ARGS:\n",
        "        - path: string - the path of the image\n",
        "        - bboxes: (N,4) ndarray; N is the number of non-overlapping detections,\n",
        "                  and each row is [x_min, y_min, x_max, y_max]\n",
        "    RETURN:\n",
        "        - plt.show(): plot of the image together with the detected bounding boxes\n",
        "    \"\"\"\n",
        "    \n",
        "    img_name=os.listdir(path)\n",
        "    n_bb=len(bboxes)\n",
        "        \n",
        "    fig, ax = plt.subplots()\n",
        "    img = cv2.imread(os.path.join(path, img_name[0]))\n",
        "    img = color.rgb2gray(img)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.axis('on')\n",
        "    \n",
        "    if n_bb!=0: \n",
        "        print(f\"List of bounding boxes coordinates (x_min, y_min, x_max, y_max): \\n\")\n",
        "       \n",
        "        for i in range(n_bb):\n",
        "                print(f\"{i+1} - ({bboxes[i][0]:.2f}, {bboxes[i][1]:.2f}, {bboxes[i][2]:.2f}, {bboxes[i][3]:.2f})\")\n",
        "                ax.add_patch(plt.Rectangle((bboxes[i][0],bboxes[i][1]), \n",
        "                                        bboxes[i][2]-bboxes[i][0], bboxes[i][3]-bboxes[i][1], \n",
        "                                        edgecolor='red',alpha=0.3, lw=2, facecolor='none'))\n",
        "                ax.text(bboxes[i][0], bboxes[i][1], \n",
        "                          str(i+1), ha='left', va='top',color=\"red\")   \n",
        "    else:\n",
        "        print(\"No bounding boxes found! Image without faces...\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "    return plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6db192f",
      "metadata": {
        "id": "f6db192f"
      },
      "source": [
        "## HARD MINING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3547ede1",
      "metadata": {
        "id": "3547ede1"
      },
      "outputs": [],
      "source": [
        "#function which defines the hard mining method, where patches with a not high enough confidence \n",
        "#are added to the augmented negative set\n",
        "def hard_negative_mining(hard_neg_set,neg_set,pos_set, n_hard_mined=5000):\n",
        "\n",
        "    \"\"\"\n",
        "    FUNC: takes a defined number of npatches with confidences lower than a defined threshold, add them to the negative images set \n",
        "          and re-train the model in order to reduce false positive detections \n",
        "          *** Use only in presence of many false positives, since it's a bit time consuming!\n",
        "    ARGS:\n",
        "        - hard_neg_set: (M,2) ndarray; M is the number of patches with confidence lower than a negative threshold \n",
        "                        and each row is width and height\n",
        "        - neg_set: (N,2) ndarray; N is the number of negative images and each row is width and height\n",
        "        - pos_set: (P,2) ndarray; P is the number of positive images and each row is width and height\n",
        "        - n_hard_mined: constant; number of patches used for hard mining\n",
        "\n",
        "    RETURN:\n",
        "\n",
        "        - neg_set: (K,2) ndarray; K=N+n*M is the number of negative images plus slected nageative patches\n",
        "                   and each row is width and height\n",
        "    \"\"\"\n",
        "\n",
        "    n_hard_neg=np.array(hard_neg_set).shape[0]\n",
        "    hard_neg_subset=[]\n",
        "    i=0\n",
        "    \n",
        "    while i < n_hard_mined:\n",
        "        k=np.random.choice(n_hard_neg,1)[0]\n",
        "        hard_neg_subset.append(hard_neg_set[k])\n",
        "        i+=1\n",
        "\n",
        "    neg_set=np.concatenate((neg_set, hard_neg_subset))\n",
        "    print(\"\\nHard negative mining COMPLETED!\")\n",
        "    print(\"----------------------------------------------------------------------------------------------------------\\n\")\n",
        "\n",
        "    return neg_set"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db522ad1",
      "metadata": {
        "id": "db522ad1"
      },
      "source": [
        "## FACEFINDER CLASS DEFINITION"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FaceFinder:\n",
        "\n",
        "  \"\"\"\n",
        "  CLASS: face detection of faces inside a picture provided as input\n",
        "\n",
        "  ATTRIBUTES:\n",
        "        - pos_k: constant; multiplier factor for data augmentation of positive images dataset\n",
        "        - neg_k: constant; multiplier factor for data augmentation of negative images dataset\n",
        "        - filename: str; path where the trained model will be saved\n",
        "        - URL_image: str, URL link of the image om which the face detection will be performed\n",
        "  RETURN:\n",
        "        - model: (TO BE USED BY SAVE_MODEL AND hard_mining METHODS) \n",
        "                  the model fitted with best found estimators \n",
        "        - aug_neg_set: (TO BE USED BY hard_mining METHOD) \n",
        "                        N is the number of negative images and each row is width and height\n",
        "        - face detection plot: plot of the image together with the detected bounding boxes\n",
        "        - hard_neg_set: (M,2) ndarray; (TO BE USED BY hard_mining METHOD) \n",
        "                         M is the number of patches with confidence lower than a negative threshold and each row is width and height\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  def __init__(self, pos_k, neg_k, filename, URL_image):\n",
        "      self.pos_k=pos_k\n",
        "      self.neg_k=neg_k\n",
        "      self.filename=filename\n",
        "      self.URL_image=URL_image\n",
        "\n",
        "\n",
        "  def train(self):\n",
        "      \n",
        "      aug_pos_set=img_pos_augmentation(pos_set,self.pos_k)\n",
        "      aug_neg_set=img_neg_augmentation(neg_set,self.neg_k)\n",
        "      model=train_classifier(aug_pos_set,aug_neg_set)\n",
        "\n",
        "      return model, aug_neg_set\n",
        "  \n",
        "  \n",
        "  def save_model(self, do_save=False):\n",
        "      self.do_save=do_save\n",
        "      if self.do_save:\n",
        "        pickle.dump(model, open(self.filename, 'wb'))\n",
        "      \n",
        "\n",
        "  \n",
        "  def load_model(self, do_load=False):\n",
        "      self.do_load=do_load\n",
        "      if self.do_load:\n",
        "        model = pickle.load(open(self.filename, 'rb'))\n",
        "      \n",
        "\n",
        "\n",
        "  def detect(self):\n",
        "\n",
        "      path=\"test\"\n",
        "      URL_image=self.URL_image\n",
        "      os.system('wget %s' %URL_image)\n",
        "      !mkdir test\n",
        "      !mv *.jpg test/\n",
        "      bboxes, confidences, hard_neg_set=sliding_window(path,verbose=True)\n",
        "      face_detection_plot=show_bboxes(path,bboxes)\n",
        "\n",
        "      return face_detection_plot, hard_neg_set\n",
        "\n",
        "       \n",
        "  def hard_mining(self, hard_neg_set, aug_neg_set, do_mining=False):\n",
        "\n",
        "    \"\"\"\n",
        "    ATTRIBUTES:\n",
        "          -hard_neg_set: (M,2) ndarray; (RETURN VALUE OF detect METHOD) \n",
        "                                        M is the number of patches with confidence lower than a negative threshold and each row is width and height\n",
        "          - aug_neg_set: (N,2) ndarray; (RETURN VALUE OF train METHOD) \n",
        "                                        N is the number of negative images and each row is width and height\n",
        "          - do_mining: boolean; if hard_mining is desidered it's valued True and the method is run\n",
        "    \"\"\"\n",
        "\n",
        "    self.hard_neg_set=hard_neg_set\n",
        "    self.aug_neg_set=aug_neg_set\n",
        "    self.do_mining=do_mining\n",
        "\n",
        "    if self.do_mining:\n",
        "      aug_pos_set=img_pos_augmentation(pos_set,self.pos_k)\n",
        "      aug_neg_set=hard_negative_mining(self.hard_neg_set,self.aug_neg_set,aug_pos_set)\n",
        "      model=train_classifier(aug_pos_set,aug_neg_set)\n",
        "      self.detect()\n",
        "      print(\"\\nHard negative mining STARTED!\")\n",
        "      print(\"----------------------------------------------------------------------------------------------------------\\n\")\n",
        "    else:\n",
        "      print(\"\\nHard negative mining NOT performed\")\n",
        "        \n",
        "      \n",
        "      \n",
        "\n"
      ],
      "metadata": {
        "id": "rpWxlhfbtHkp"
      },
      "id": "rpWxlhfbtHkp",
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RUNNING CODE"
      ],
      "metadata": {
        "id": "vmMB1amsEUx2"
      },
      "id": "vmMB1amsEUx2"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The dataset used to train the model will be the Caltech dataset, containing respectively: \")\n",
        "print(f\"{np.array(pos_set).shape[0]} positive images (with at least a face), with size ({np.array(pos_set).shape[1]},{np.array(pos_set).shape[2]})\")\n",
        "print(f\"{np.array(neg_set).shape[0]} negative images (with no faces), with size ({np.array(neg_set).shape[1]},{np.array(neg_set).shape[2]})\")\n",
        "print(\"\\n---------------------------------------------------------------------------------------------------------\")\n",
        "\n",
        "keep_going=\"\"\n",
        "i=0\n",
        "while str(keep_going.lower()) !=\"no\":\n",
        "\n",
        "  aug=input(\"Do you want to perform a data augmentation on the train dataset (it may help in improving detection)? [yes/press any key for no]: \")\n",
        "  if aug.lower()== \"yes\":\n",
        "    pos_k=int(input(\"Insert multiplier factor for data augmentation of positive dataset: \"))\n",
        "    neg_k=int(input(\"Insert multiplier factor for data augmentation of negative dataset: \"))\n",
        "  else:\n",
        "    pos_k=1\n",
        "    neg_k=1\n",
        "\n",
        "  do_save=input(\"Do you want to save the trained model for future use?: \")\n",
        "  if do_save.lower()==\"yes\":\n",
        "    do_save=True\n",
        "    filename=input(\"Insert the path where the model will be saved: \")\n",
        "  else:\n",
        "    do_save=False\n",
        "\n",
        "  do_load=False\n",
        "  if i>0:\n",
        "    do_load=input(\"Do you want to load an already trained model?: \")\n",
        "    if do_load.lower()==\"yes\":\n",
        "      do_load=True\n",
        "      filename=input(\"Insert the path where the model is saved: \")\n",
        "    else:\n",
        "      do_load=False\n",
        "\n",
        "  URL_image=input(\"Insert the URL link for the image for which you want to detect faces: \")\n",
        "\n",
        "  do_mining=input(\"Do you want to perform an hard negative mining (it may improve the detection reducing false positives)?: \")\n",
        "  if do_mining.lower()==\"yes\":\n",
        "    do_mining=True\n",
        "  else:\n",
        "    do_mining=False\n",
        "\n",
        "  print(\"\\n----------------------------------------------------------------------------------------------------------\\n\")\n",
        "  time.sleep(2)\n",
        "  print(\"3\")\n",
        "  time.sleep(1)\n",
        "  print(\"2\")\n",
        "  time.sleep(1)\n",
        "  print(\"1\")\n",
        "  time.sleep(1)\n",
        "  print(\"STARTING...\\n\")\n",
        "  time.sleep(2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  face_finder = FaceFinder(pos_k, neg_k, filename, URL_image)\n",
        "  if do_load==False:\n",
        "    model, aug_neg_set = face_finder.train()\n",
        "  else:\n",
        "    face_finder.load_model()\n",
        "  face_finder.save_model()\n",
        "  _, hard_neg_set = face_finder.detect()\n",
        "  face_finder.hard_mining(hard_neg_set, aug_neg_set, do_mining)\n",
        "\n",
        "  time.sleep(2)\n",
        "  keep_going=input(\"Do you want to performed detection on another image? [Press any key for yes/no]: \")\n",
        "  i+=1"
      ],
      "metadata": {
        "id": "lZJ_CqcQE7pK"
      },
      "id": "lZJ_CqcQE7pK",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}